{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573a975b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede12269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000014CC0DCA4D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000014CC0DFC6D0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-it\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d12503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Salman, it's nice to meet you!\\n\\nAs Chief AI Engineer, what kind of projects are you working on these days?  I'm always interested to hear about the latest advancements in AI.  \\n\\nPerhaps you can tell me about:\\n\\n* **The most exciting AI application you've encountered recently?**\\n* **The biggest challenge you face in your role?**\\n* **What you think the future holds for AI?**\\n\\n\\nI'm eager to learn more about your work!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 22, 'total_tokens': 130, 'completion_time': 0.196363636, 'prompt_time': 0.00206649, 'queue_time': 0.243314313, 'total_time': 0.198430126}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--7f05bb7d-6665-462e-931f-a6cc4ca9b291-0', usage_metadata={'input_tokens': 22, 'output_tokens': 108, 'total_tokens': 130})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi, My Name is Salman and I am Chief AI Engineer.\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e1297d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name or what you do. Every interaction we have is a fresh start.\\n\\nIf you'd like to tell me your name and what you do, I'm happy to learn!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 22, 'total_tokens': 79, 'completion_time': 0.103636364, 'prompt_time': 0.002093591, 'queue_time': 0.243595808, 'total_time': 0.105729955}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--5a025188-b6af-4eb4-a825-982fd2289c5b-0', usage_metadata={'input_tokens': 22, 'output_tokens': 57, 'total_tokens': 79})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"Hi,do you know my name? or what i do ?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e7a13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You're right! As a large language model, I have no memory of past conversations.  So, while you told me your name is Salman and that you're a Chief AI Engineer, I don't retain that information from our previous interaction. \\n\\nI treat each conversation as a fresh start.  \\n\\nIs there anything specific I can help you with today, Salman?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 89, 'total_tokens': 170, 'completion_time': 0.147272727, 'prompt_time': 0.00393586, 'queue_time': 0.24467388899999998, 'total_time': 0.151208587}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--371bd781-3f2c-4c2f-89d7-c51f18e9a878-0', usage_metadata={'input_tokens': 89, 'output_tokens': 81, 'total_tokens': 170})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, my name is Salman and I am cheif AI Engineer\"),\n",
    "        AIMessage(content=\"Hello Salman, it's nice to meet you! That's a fascinating title.  \\n\\nWhat kind of AI projects are you working on?  I'm always eager to learn about new developments in the field\"),\n",
    "        HumanMessage(content=\"Hi,do you know my name? or what i do ?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed61c88",
   "metadata": {},
   "source": [
    "\n",
    "Message Historry and Stateful Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0e2b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello Salman, it's a pleasure to meet you! \\n\\nThat's fascinating, being a Gen AI Professor. What exciting things are you working on in your field? Do you have any students working on particularly interesting projects? I'm always eager to learn more about the advancements being made in AI.\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 21, 'total_tokens': 87, 'completion_time': 0.12, 'prompt_time': 0.002095299, 'queue_time': 0.262767866, 'total_time': 0.122095299}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--17d4ec3d-a877-4a29-a9df-155f44ae9608-0' usage_metadata={'input_tokens': 21, 'output_tokens': 66, 'total_tokens': 87}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "# Function to get or create session history\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Wrap your model with message history handling\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    model,\n",
    "    get_session_history=get_session_history\n",
    ")\n",
    "\n",
    "# Now you can use it like this\n",
    "response = with_message_history.invoke(\n",
    "    {\"input\": \"Hi my name is Salman and I am a Gen AI Professor\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session1\"}}\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1611db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ecde962",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is Salman and I am Gen AI professor\")],\n",
    "    config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07fe1a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Salman! It's a pleasure to meet you. \\n\\nBeing a Gen AI professor must be fascinating. What aspects of generative AI are you most passionate about teaching?  \\n\\nI'm always eager to learn more about this rapidly developing field. Perhaps you could tell me about some of the exciting research or projects your students are working on?\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62133b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0e4b28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'd be happy to know! ðŸ˜Š\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salmanchat={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=salmanchat\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af8052bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Salman, it's nice to meet you! ðŸ‘‹ \\n\\nIs there anything I can help you with today?\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey my name is Salman\")],\n",
    "    config=salmanchat\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5f262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Salman! ðŸ˜Š  \\n\\nI remember that from our last conversation.  \\n\\nDo you need me to remember anything else for you?\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what's my name?\")],\n",
    "    config=salmanchat\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b95d1c0",
   "metadata": {},
   "source": [
    "Conclusion \n",
    "\n",
    "Remember: \n",
    "- ChatMessageHistory(store conversstion histories)\n",
    "- RunnableWithMessageHistory(allow you to connect with model with session based approach)\n",
    "- Each session has a unique ID so multiple users don't mix context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0dbf1d",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01957bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpul Assistant.Answer all the questions to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccd1d97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Salman!  \\n\\nIt's nice to meet you. What can I do to help you today? ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 31, 'total_tokens': 59, 'completion_time': 0.050909091, 'prompt_time': 0.002293579, 'queue_time': 0.237465859, 'total_time': 0.05320267}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--943e32f9-fd6c-44ac-b177-d8194e2be960-0', usage_metadata={'input_tokens': 31, 'output_tokens': 28, 'total_tokens': 59})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Salman\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93e18151",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history=get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f71c3c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Salman1 = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is Salman\")],\n",
    "    config=config\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6691739f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Salman, it's nice to meet you!\\n\\nIs there anything I can help you with today?  Perhaps you have some questions about generative AI, or maybe you'd like to discuss a particular project? I'm here to assist in any way I can. \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 169, 'total_tokens': 229, 'completion_time': 0.109090909, 'prompt_time': 0.008416408, 'queue_time': 0.238899199, 'total_time': 0.117507317}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--61ebe9bb-9305-4498-afe2-883719f7632d-0', usage_metadata={'input_tokens': 169, 'output_tokens': 60, 'total_tokens': 229})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d288bfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Salman. ðŸ˜Š  \\n\\nI'm here to help, so if you have any other questions or need anything, just ask!\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what's my name?\")],\n",
    "    config=salmanchat\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cht",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
